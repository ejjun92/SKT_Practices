{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"VGGNet.ipynb","version":"0.3.2","provenance":[{"file_id":"1bS0JIU59dU7BthWliuu2kgSMNb2RVTMv","timestamp":1523422155966}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"kUziHqXmF5B-","colab_type":"code","colab":{}},"source":["# http://pytorch.org/\n","from os import path\n","from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n","platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n","\n","accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n","\n","!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.3.0.post4-{platform}-linux_x86_64.whl torchvision\n","import torch"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kbrl4jxKGFo8","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn as nn\n","from torch.autograd import Variable\n","import torchvision.datasets as datasets\n","import torchvision.transforms as transforms\n","\n","import torchvision.models as models\n","pre_vgg=models.vgg19_bn(pretrained=True)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"f0oDpcezKlYK","colab_type":"text"},"source":["## **VGG-19 NETWORK 구성하기**"]},{"cell_type":"code","metadata":{"id":"EAZWOam78RgJ","colab_type":"code","colab":{}},"source":["class ConvLayer1(nn.Module):\n","\n","    def __init__(self, number_of_conv, in_dim, out_dim):\n","        super(ConvLayer1, self).__init__()\n","        \n","        self.in_dim = in_dim\n","        self.out_dim = out_dim\n","        \n","        self.main = nn.Sequential(nn.Conv2d(self.in_dim, ??, kernel_size=3, padding=1),                    \n","                                  nn.BatchNorm2d(??),\n","                                  nn.ReLU()\n","                                  ??\n","                                  ??\n","                                  ??\n","                                  ??\n","                                  ??\n","                                  ??\n","                                  ... \n","                                 )\n","        \n","    def forward(self, x):\n","        out = self.main(x)\n","        return out"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vN1mbLpA8Y5q","colab_type":"code","colab":{}},"source":["class ConvLayer2(nn.Module):\n","\n","    def __init__(self, number_of_conv, in_dim, out_dim):\n","        super(ConvLayer2, self).__init__()\n","        \n","        self.in_dim = in_dim\n","        self.out_dim = out_dim\n","        \n","        self.main = nn.Sequential(nn.Conv2d(self.in_dim, ??, kernel_size=3, padding=1),                    \n","                                  nn.BatchNorm2d(??),\n","                                  nn.ReLU()\n","                                  ??\n","                                  ??\n","                                  ??\n","                                  ??\n","                                  ??\n","                                  ??\n","                                  ... \n","                                 )\n","        \n","    def forward(self, x):\n","        out = self.main(x)\n","        return out"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mGFf0M428Y90","colab_type":"code","colab":{}},"source":["class ConvLayer3(nn.Module):\n","\n","    def __init__(self, number_of_conv, in_dim, out_dim):\n","        super(ConvLayer3, self).__init__()\n","        \n","        self.in_dim = in_dim\n","        self.out_dim = out_dim\n","        \n","        self.main = nn.Sequential(nn.Conv2d(self.in_dim, ??, kernel_size=3, padding=1),                    \n","                                  nn.BatchNorm2d(??),\n","                                  nn.ReLU()\n","                                  ??\n","                                  ??\n","                                  ??\n","                                  ??\n","                                  ??\n","                                  ??\n","                                  ... \n","                                 )\n","        \n","    def forward(self, x):\n","        out = self.main(x)\n","        return out"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zUMiCSjf8ZE0","colab_type":"code","colab":{}},"source":["class ConvLayer4(nn.Module):\n","\n","    def __init__(self, number_of_conv, in_dim, out_dim):\n","        super(ConvLayer4, self).__init__()\n","        \n","        self.in_dim = in_dim\n","        self.out_dim = out_dim\n","        \n","        self.main = nn.Sequential(nn.Conv2d(self.in_dim, ??, kernel_size=3, padding=1),                    \n","                                  nn.BatchNorm2d(??),\n","                                  nn.ReLU()\n","                                  ??\n","                                  ??\n","                                  ??\n","                                  ??\n","                                  ??\n","                                  ??\n","                                  ... \n","                                 )\n","        \n","    def forward(self, x):\n","        out = self.main(x)\n","        return out"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WHJfg5828ZKi","colab_type":"code","colab":{}},"source":["class ConvLayer5(nn.Module):\n","\n","    def __init__(self, number_of_conv, in_dim, out_dim):\n","        super(ConvLayer5, self).__init__()\n","        \n","        self.in_dim = in_dim\n","        self.out_dim = out_dim\n","        \n","        self.main = nn.Sequential(nn.Conv2d(self.in_dim, ??, kernel_size=3, padding=1),                    \n","                                  nn.BatchNorm2d(??),\n","                                  nn.ReLU()\n","                                  ??\n","                                  ??\n","                                  ??\n","                                  ??\n","                                  ??\n","                                  ??\n","                                  ... \n","                                 )\n","        \n","    def forward(self, x):\n","        out = self.main(x)\n","        return out"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"t64ZySpa-4uH","colab_type":"code","outputId":"439e7010-40f9-4e1a-c4ac-be9a250e8ed0","executionInfo":{"status":"error","timestamp":1525870840473,"user_tz":-540,"elapsed":1296,"user":{"displayName":"Keetae park","photoUrl":"//lh4.googleusercontent.com/-HRf48e0fZvg/AAAAAAAAAAI/AAAAAAAAARU/UAGYNn-FRto/s50-c-k-no/photo.jpg","userId":"112755870975618660481"}},"colab":{"base_uri":"https://localhost:8080/","height":171}},"source":["class VGG19(nn.Module):\n","  \n","    def __init__(self):\n","        super(VGG19, self).__init__()\n","        \n","        self.convlayer1 = ConvLayer1\n","        self.convlayer2 = ConvLayer2\n","        self.convlayer3 = ConvLayer3\n","        self.convlayer4 = ConvLayer4\n","        self.convlayer5 = ConvLayer5\n","        self.linear = nn.Sequential(\n","            nn.Linear(512, ??),\n","            nn.ReLU(),\n","            nn.Linear(512, ??),\n","            nn.ReLU(),\n","            nn.Linear(128, ??),\n","        )\n","    def forward(self, input):\n","        out = self.convlayer1(input)    \n","        out = self.convlayer2(out)\n","        out = self.convlayer3(out)\n","        out = self.convlayer4(out)\n","        out = self.convlayer5(out).squeeze() # 16 x 512 x 1 x 1에서 뒤 1 x 1 축약 \n","        out = self.linear(out)\n","        return out\n"],"execution_count":0,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-b0dc4a3561bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mConvLayer5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'ConvLayer5' is not defined"]}]},{"cell_type":"code","metadata":{"id":"fiOksgXRGF-U","colab_type":"code","colab":{}},"source":["vgg19 = VGG19()\n","print(vgg19)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_E5e0bDyXmW6","colab_type":"code","colab":{}},"source":["# number of parameters\n","def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","count_parameters(vgg19)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1sITqCxfOWjv","colab_type":"text"},"source":["# VGG-19로 CIFAR-10 CLASSIFICATION 트레이닝하기"]},{"cell_type":"code","metadata":{"id":"-f1-pzCsPq6W","colab_type":"code","colab":{}},"source":["# set hyperparameters\n","batch_size = 64\n","learning_rate = 0.001\n","num_epochs = 3"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qajNxxseGGB6","colab_type":"code","colab":{}},"source":["# import torchvision.datasets as datasets\n","\n","train_dataset = datasets.CIFAR10(root='./data/',       # 50000장\n","                            train=True, \n","                            transform=transforms.ToTensor(),\n","                            download=True)\n","\n","test_dataset = datasets.CIFAR10(root='./data/',        # 10000장\n","                           train=False, \n","                           transform=transforms.ToTensor())\n","\n","# 데이터 로더\n","train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n","                                           batch_size=batch_size, \n","                                           shuffle=True)\n","\n","test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n","                                          batch_size=batch_size, \n","                                          shuffle=True)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gf4OKtLe5mbx","colab_type":"text"},"source":["#CIFAR-10\n","\n","50000 training images \\\\\n","10000 validation images \\\\\n"," \\\\\n","10 classes = [airplane, car, truck, frog, ...]\n"," \\\\\n","for more info, https://www.cs.toronto.edu/~kriz/cifar.html \n","\n"]},{"cell_type":"code","metadata":{"id":"vdz7yTsFOtuf","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","\n","###########################  cifar10 사진 보여주기용 ############################\n","def show_cifar10():\n","  for images, _ in train_loader:\n","    plt.figure(figsize=(8,8))\n","    images_to_show = images.numpy().transpose((0,2,3,1))\n","\n","    for a in range(331, 340):    \n","      plt.subplot(a)\n","      plt.imshow(images_to_show[a-331])\n","      plt.xticks([])\n","      plt.yticks([])    \n","    plt.show()   \n","    break\n","  return 0\n","\n","###########################로스 그래프를 뽑기 위한 함수 ##########################\n","def loss_plot(acc):  \n","  plt.plot(acc)\n","  plt.xlabel('log')\n","  plt.ylabel('accuracy')\n","  plt.grid(True)\n","#   plt.savefig(\"test.png\")\n","  plt.show()\n","  return 0\n","\n","######################### 런타임 시간을 측정하기 위한 함수 #######################\n","import time\n","class Timer():    \n","    def __init__(self):\n","        self.cur_t = time.time()\n","\n","    def tic(self):\n","        self.cur_t = time.time()\n","\n","    def toc(self):\n","        return time.time() - self.cur_t\n","\n","    def tocStr(self, t=-1):\n","        if (t == -1):\n","            return str(datetime.timedelta(seconds=np.round(time.time() - self.cur_t, 3)))[:-4]\n","        else:\n","            return str(datetime.timedelta(seconds=np.round(t, 3)))[:-4]\n","          \n","######################### 트레이닝 현황 테스트를 위한 함수 #######################\n","\n","def test_on_cifar10(model, accuracy_list):  \n","    # Test the Model       \n","  model.eval()    # Change model to 'eval' mode (BN uses moving mean/var).\n","  correct = 0\n","  total = 0\n","  for j, (images, labels) in enumerate(test_loader):\n","      images = Variable(images).cuda()\n","      outputs = model(images)\n","      _, predicted = torch.max(outputs.data, 1)\n","      total += labels.size(0)\n","      correct += (predicted.cpu() == labels).sum()\n","      if (j+1)%100==0:\n","        break\n","\n","  print('Test Accuracy of the model on the 100 test images: %d %%' % (100 * correct / total))\n","  accuracy_list.append(100 * correct / total) \n","  return model, accuracy_list\n","          \n","################################################################################"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZVfe387o5eVm","colab_type":"code","colab":{}},"source":["show_cifar10()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bd15jgp-Thej","colab_type":"code","colab":{}},"source":["tell_time = Timer()\n","iter_time = 0\n","\n","vgg19 = vgg19.cuda()\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(vgg19.parameters(), lr=learning_rate)\n","\n","accuracy_list = []\n","for epoch in range(num_epochs):\n","  vgg19.train()\n","  for i, (images, labels) in enumerate(train_loader):\n","      images = Variable(images).cuda()\n","      labels = Variable(labels).cuda()\n","\n","      # Forward + Backward + Optimize\n","      optimizer.zero_grad()\n","      outputs = vgg19(images)\n","      loss = criterion(outputs, labels)\n","      loss.backward()\n","      optimizer.step()\n","\n","      if (i+1) % 100 == 0:\n","        print ('Epoch [%d/%d], Iter [%d/%d] Loss: %.4f, iter_time: %2.2f' \n","               %(epoch+1, num_epochs, i+1, len(train_dataset)//batch_size, loss.data[0], tell_time.toc()-iter_time))\n","        iter_time = tell_time.toc()    \n","\n","        accuracy_list = test_on_cifar10(vgg19, accuracy_list)\n","\n","loss_plot(accuracy_list)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2wszStGbThqT","colab_type":"code","colab":{}},"source":["import torchvision.models as models\n","pre_vgg = models.vgg19_bn(pretrained=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JBjKGJ7_lJxK","colab_type":"code","colab":{}},"source":["class pretrained_vgg(nn.Module):\n","    def __init__(self):\n","        super(pretrained_vgg, self).__init__()\n","        self.features = nn.Sequential(   \n","            *list(pre_vgg.features.children())\n","        )\n","        self.linear = nn.Sequential(\n","            nn.Linear(512, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 128),\n","            nn.ReLU(),\n","            nn.Linear(128, 10),\n","        )\n","    def forward(self, x):\n","        out = self.features(x).squeeze()\n","        out = self.linear(out)\n","        return out\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8BWlG9AWlT3k","colab_type":"code","colab":{}},"source":["  _vgg = pretrained_vgg()\n","  \n","  tell_time = Timer()\n","  iter_time = 0\n","\n","  _vgg = _vgg.cuda()\n","  criterion = nn.CrossEntropyLoss()\n","  optimizer = torch.optim.Adam(_vgg.parameters(), lr=learning_rate)\n","  \n","  accuracy_list = []\n","  for epoch in range(num_epochs):\n","    \n","    for i, (images, labels) in enumerate(train_loader):\n","        images = Variable(images).cuda()\n","        labels = Variable(labels).cuda()\n","\n","        # Forward + Backward + Optimize\n","        optimizer.zero_grad()\n","        outputs = _vgg(images)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        if (i+1) % 100 == 0:\n","          print ('Epoch [%d/%d], Iter [%d/%d] Loss: %.4f, iter_time: %2.2f' \n","                 %(epoch+1, num_epochs, i+1, len(train_dataset)//batch_size, loss.data[0], tell_time.toc()-iter_time))\n","          iter_time = tell_time.toc()    \n","          \n","          accuracy_list = test_on_cifar10(_vgg, accuracy_list)\n","          \n","  loss_plot(accuracy_list)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wEZapNEeBJAK","colab_type":"text"},"source":["  \\\\\n","   \\\\\n","    \\\\"]}]}